{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Type, Any, Callable, Union, List, Dict, Optional, cast\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict \n",
    "from torchvision.models.resnet import *\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "class WebDataset(Dataset):\n",
    "    def __init__(self, images, categories, transform=None, target_transform=None):\n",
    "        self.images = images\n",
    "        self.categories = le.fit_transform(categories)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], torch.tensor(self.categories[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('items_shuffle_1000.json')\n",
    "json_data = json.load(f)\n",
    "# data_subset = json_data[:5]\n",
    "dataset = WebDataset(images, categories)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class ResNet101(models.ResNet):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, **kwargs):\n",
    "        # Start with the standard resnet101\n",
    "        super().__init__(\n",
    "            block=models.resnet.Bottleneck,\n",
    "            layers=[3, 4, 23, 3],\n",
    "            num_classes=num_classes,\n",
    "            **kwargs\n",
    "        )\n",
    "        if pretrained:\n",
    "            state_dict = torch.hub.load_state_dict_from_url(\n",
    "                \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\",\n",
    "                progress=True\n",
    "            )\n",
    "            self.load_state_dict(state_dict)\n",
    " \n",
    "    # Reimplementing forward pass.\n",
    "    # Replacing the forward inference defined here \n",
    "    # http://tiny.cc/23pmmz\n",
    "    def _forward_impl(self, x):\n",
    "        # Standard forward for resnet\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    " \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    " \n",
    "        # Notice there is no forward pass through the original classifier.\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResNet101(pretrained=True)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model2.to(device)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "features = torch.empty((0, 2048), dtype=torch.float32)\n",
    "batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
    "for i, (images, labels) in enumerate(dataloader):\n",
    "        \n",
    "        # Move images to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        with torch.inference_mode():\n",
    "            outputs = model2(images)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        features = np.concatenate((features, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and move the coordinates so they fit [0; 1] range\n",
    "def scale_to_01_range(x):\n",
    "    # compute the distribution range\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    " \n",
    "    # move the distribution so that it starts from zero\n",
    "    # by extracting the minimal value from all its values\n",
    "    starts_from_zero = x - np.min(x)\n",
    " \n",
    "    # make the distribution fit [0; 1] by dividing by its range\n",
    "    return starts_from_zero / value_range\n",
    " \n",
    "# extract x and y coordinates representing the positions of the images on T-SNE plot\n",
    "tx = tsne[:, 0]\n",
    "ty = tsne[:, 1]\n",
    " \n",
    "tx = scale_to_01_range(tx)\n",
    "ty = scale_to_01_range(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap('Dark2')\n",
    "print(len(cmap.colors))\n",
    "# len colors >= num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a matplotlib plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = cmap.colors\n",
    " \n",
    "# for every class, we'll add a scatter plot separately\n",
    "for j, label in enumerate(list(le.classes_)):\n",
    "    # find the samples of the current class in the data\n",
    "    indices = [i for i, l in enumerate(le.inverse_transform(dataset.categories)) if l == label]\n",
    " \n",
    "    # extract the coordinates of the points of this class only\n",
    "    current_tx = np.take(tx, indices)\n",
    "    current_ty = np.take(ty, indices)\n",
    " \n",
    "    # convert the class color to matplotlib format\n",
    "    # color = np.array(colors_per_class[label], dtype=np.float) / 255\n",
    " \n",
    "    # add a scatter plot with the corresponding color and label\n",
    "    ax.scatter(current_tx, current_ty, c=colors[j], label=label)\n",
    " \n",
    "# build a legend using the labels we set previously\n",
    "ax.legend(loc='best')\n",
    " \n",
    "# finally, show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
